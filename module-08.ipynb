{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import random\n",
    "from collections import namedtuple\n",
    "import math\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(file_name: str) -> list[list]:\n",
    "    data = []\n",
    "    file = open(file_name, \"r\")\n",
    "    for line in file:\n",
    "        datum = line.rstrip().split(\",\")\n",
    "        data.append(datum)\n",
    "    random.shuffle(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folds(xs: list, n: int) -> list[list[list]]:\n",
    "    k, m = divmod(len(xs), n)\n",
    "    # be careful of generators...\n",
    "    return list(xs[i * k + min(i, m):(i + 1) * k + min(i + 1, m)] for i in range(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## count_labels\n",
    "\n",
    "### Args:\n",
    "* **data** : List of lists, where each inner list represents a row of data. The first element of each row is the label ('e' or 'p').\n",
    "\n",
    "### Returns: \n",
    "* **returns (count_e, count_p)** A tuple where `count_e` is the number of rows labeled 'e' and `count_p` is the number of rows labeled 'p'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_labels(data):\n",
    "    count_e = 0 \n",
    "    count_p = 0\n",
    "    for row in data: \n",
    "        label = row[0]\n",
    "        if label == 'e':\n",
    "            count_e += 1\n",
    "        elif label == 'p':\n",
    "            count_p += 1\n",
    "    return count_e, count_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert count_labels([['e'], ['p'], ['e'], ['p']]) == (2, 2)\n",
    "assert count_labels([['e'], ['e'], ['e']]) == (3, 0)\n",
    "assert count_labels([]) == (0, 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate_entropy_fullset\n",
    "\n",
    "### Args:\n",
    "* **data** : List of lists, where each inner list represents a row of data. The first element of each row is the label ('e' or 'p'). This data is used to calculate the entropy of the full set.\n",
    "\n",
    "### Returns: \n",
    "* **returns entropy** The entropy value of the full dataset, calculated using the proportion of positive ('e') and negative ('p') labels. If the dataset is empty, returns 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy_fullset(data):\n",
    "    pos, neg = count_labels(data)\n",
    "    total = pos + neg\n",
    "    if total == 0: \n",
    "        return 0\n",
    "    prob_pos = pos/total\n",
    "    prob_neg = neg/total\n",
    "    entropy = 0\n",
    "    if prob_pos > 0: \n",
    "        entropy-= prob_pos * math.log2(prob_pos)\n",
    "    if prob_neg > 0:\n",
    "        entropy -= prob_neg * math.log2(prob_neg)\n",
    "    return entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert round(calculate_entropy_fullset([['e'], ['p']]), 4) == 1.0\n",
    "assert calculate_entropy_fullset([['e'], ['e'], ['e']]) == 0.0\n",
    "assert calculate_entropy_fullset([]) == 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get_subset\n",
    "\n",
    "### Args:\n",
    "* **data** : List of lists, where each inner list represents a row of data.\n",
    "* **attribute** : Integer representing the index of the attribute/column to filter by.\n",
    "* **value** : The value to filter the rows by, based on the specified attribute.\n",
    "\n",
    "### Returns: \n",
    "* **returns subset** A list of rows (subsets) where the value of the specified attribute matches the provided value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subset(data, attribute, value):\n",
    "    subset = []\n",
    "    for row in data: \n",
    "        if row[attribute] == value:\n",
    "            subset.append(row)\n",
    "    return subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert get_subset([['e', 1], ['p', 0], ['e', 1]], 1, 1) == [['e', 1], ['e', 1]]\n",
    "assert get_subset([['e', 1], ['p', 0], ['e', 1]], 1, 0) == [['p', 0]]\n",
    "assert get_subset([['e', 1], ['p', 0], ['e', 1]], 1, 2) == []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate_entropy_subset\n",
    "\n",
    "### Args:\n",
    "* **data** : List of lists, where each inner list represents a row of data.\n",
    "* **attribute** : Integer representing the index of the attribute/column to filter by.\n",
    "* **value** : The value to filter the rows by, based on the specified attribute.\n",
    "\n",
    "### Returns: \n",
    "* **returns (entropy, subset_size)** A tuple where:\n",
    "  * `entropy` is the entropy of the subset filtered by the given attribute and value.\n",
    "  * `subset_size` is the number of rows in the subset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy_subset(data, attribute, value):\n",
    "    subset = get_subset(data, attribute, value )\n",
    "    subset_size = len(subset)\n",
    "    pos, neg = count_labels(subset)\n",
    "    total = pos + neg\n",
    "    if total == 0: \n",
    "        return 0\n",
    "    prob_pos = pos/total\n",
    "    prob_neg = neg/total\n",
    "    entropy = 0\n",
    "    if prob_pos > 0: \n",
    "        entropy-= prob_pos * math.log2(prob_pos)\n",
    "    if prob_neg > 0:\n",
    "        entropy -= prob_neg * math.log2(prob_neg)\n",
    "    return entropy, subset_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert round(calculate_entropy_subset([['e', 1], ['p', 1]], 1, 1)[0], 4) == 1.0\n",
    "assert calculate_entropy_subset([['e', 1], ['e', 1]], 1, 1)[0] == 0.0\n",
    "assert calculate_entropy_subset([], 1, 1) == 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get_unique_values\n",
    "\n",
    "### Args:\n",
    "* **data** : List of lists, where each inner list represents a row of data.\n",
    "* **attribute** : Integer representing the index of the attribute/column to extract unique values from.\n",
    "\n",
    "### Returns: \n",
    "* **returns unique** A set containing all unique values for the specified attribute in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_values(data,attribute):\n",
    "    unique = set()\n",
    "    for row in data:\n",
    "        unique.add(row[attribute])\n",
    "    return unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert get_unique_values([['e', 1], ['p', 2], ['e', 3]], 1) == {1, 2, 3}\n",
    "assert get_unique_values([['e', 1], ['p', 1], ['e', 1]], 1) == {1}\n",
    "assert get_unique_values([], 1) == set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate_information_gain\n",
    "\n",
    "### Args:\n",
    "* **data** : List of lists, where each inner list represents a row of data.\n",
    "* **attribute** : Integer representing the index of the attribute/column for which the information gain is calculated.\n",
    "\n",
    "### Returns: \n",
    "* **returns information_gain** The information gain obtained by splitting the data on the specified attribute. It is calculated as the difference between the base entropy of the full dataset and the weighted entropy of the subsets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_information_gain(data,attribute):\n",
    "    values = get_unique_values(data,attribute)\n",
    "    base_entropy = calculate_entropy_fullset(data)\n",
    "    weighted_entropy = 0\n",
    "    total_instances = len(data) \n",
    "    for value in values: \n",
    "        sub_entropy, subset_size = calculate_entropy_subset(data,attribute,value)\n",
    "        prob = subset_size / total_instances\n",
    "        weighted_entropy += prob * sub_entropy\n",
    "    information_gain = base_entropy - weighted_entropy\n",
    "    return information_gain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert math.isclose(calculate_information_gain([['e', 1], ['p', 1], ['e', 0], ['p', 0]], 1), 4 == 1.0)\n",
    "assert calculate_information_gain([['e', 1], ['e', 0]], 1) == 0.0\n",
    "assert calculate_information_gain([], 1) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pick_best_attribute\n",
    "\n",
    "### Args:\n",
    "* **data** : List of lists, where each inner list represents a row of data.\n",
    "* **attributes** : List of integers, each representing an index of an attribute/column to evaluate.\n",
    "\n",
    "### Returns: \n",
    "* **returns best_attribute** The attribute (represented as an index) that provides the highest information gain when used to split the data. If no attribute provides a positive gain, `None` is returned.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_best_attribute(data, attributes):\n",
    "    best_attribute = None\n",
    "    max_gain = float(\"-inf\")\n",
    "    for attribute in attributes:\n",
    "        gain = calculate_information_gain(data,attribute)\n",
    "        if gain > max_gain:\n",
    "            max_gain = gain\n",
    "            best_attribute = attribute\n",
    "    return best_attribute\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert pick_best_attribute([['e', 1, 0], ['p', 0, 1], ['e', 1, 0], ['p', 0, 1]], [1, 2]) == 1\n",
    "assert pick_best_attribute([['e', 1, 1], ['p', 0, 0]], [1, 2]) in [1, 2]\n",
    "assert pick_best_attribute([], [1, 2]) == 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## is_homogeneous\n",
    "\n",
    "### Args:\n",
    "* **data** : List of lists, where each inner list represents a row of data. The first element of each row is the label to check.\n",
    "\n",
    "### Returns: \n",
    "* **returns True/False** Returns `True` if all rows in the dataset have the same label, otherwise returns `False`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_homogeneous(data):\n",
    "    label = data[0][0]\n",
    "    for row in data:\n",
    "        if row[0] != label:\n",
    "            return False \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert is_homogeneous([['e'], ['e'], ['e']]) == True\n",
    "assert is_homogeneous([['e'], ['p'], ['e']]) == False\n",
    "assert is_homogeneous([['p'], ['p'], ['p']]) == True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## majority_class\n",
    "\n",
    "### Args:\n",
    "* **data** : List of lists, where each inner list represents a row of data. The first element of each row is the label to be counted.\n",
    "\n",
    "### Returns: \n",
    "* **returns majority_class** The label that appears most frequently in the dataset. In case of a tie, it returns the first label that reaches the maximum count.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_class(data):\n",
    "    classes = {}\n",
    "    for row in data: \n",
    "        label = row[0]\n",
    "        classes[label] =  classes.get(label,0) + 1\n",
    "        return max(classes, key=classes.get)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert majority_class([['e'], ['p'], ['e']]) == 'e'\n",
    "assert majority_class([['p'], ['p'], ['e']]) == 'p'\n",
    "assert majority_class([['e'], ['p']]) == 'e'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create_leaf\n",
    "\n",
    "### Args:\n",
    "* **label** : The label assigned to the leaf node, representing the class or category for that leaf.\n",
    "\n",
    "### Returns: \n",
    "* **returns leaf** A dictionary representing a leaf node with the structure `{'type': 'leaf', 'label': label}`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_leaf(label):\n",
    "    return {'type': 'leaf', 'label': label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert create_leaf('e') == {'type': 'leaf', 'label': 'e'}\n",
    "assert create_leaf('p') == {'type': 'leaf', 'label': 'p'}\n",
    "assert create_leaf('unknown') == {'type': 'leaf', 'label': 'unknown'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create_node\n",
    "\n",
    "### Args:\n",
    "* **attribute** : The attribute/index used to split the data at this node.\n",
    "* **children** : A dictionary or list representing the child nodes that result from splitting on the attribute.\n",
    "\n",
    "### Returns: \n",
    "* **returns node** A dictionary representing a decision tree node with the structure `{'type': 'node', 'attribute': attribute, 'children': children}`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_node(attribute, children):\n",
    "    return {'type': 'node', 'attribute': attribute, 'children': children}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert create_node(1, {'value1': 'child1', 'value2': 'child2'}) == {'type': 'node', 'attribute': 1, 'children': {'value1': 'child1', 'value2': 'child2'}}\n",
    "assert create_node(2, {}) == {'type': 'node', 'attribute': 2, 'children': {}}\n",
    "assert create_node(3, {'value1': 'child1'}) == {'type': 'node', 'attribute': 3, 'children': {'value1': 'child1'}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get_remaining_attributes\n",
    "\n",
    "### Args:\n",
    "* **attributes** : List of integers representing the indices of all attributes available for selection.\n",
    "* **used_attribute** : An integer representing the index of the attribute that has already been used and should be excluded.\n",
    "\n",
    "### Returns: \n",
    "* **returns remaining_attributes** A list of attributes that excludes the `used_attribute`, containing only the remaining attributes that can still be used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_remaining_attributes(attributes, used_attribute):\n",
    "    remaining_attributes = []\n",
    "    for attribute in attributes:\n",
    "        if attribute != used_attribute:\n",
    "            remaining_attributes.append(attribute)\n",
    "    return remaining_attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## id3\n",
    "This function implements the ID3 algorithm for decision tree generation. It recursively selects the best attribute to split the data based on information gain, creating a tree where each node represents a decision, and each leaf represents a class label. The function stops either when the data is homogeneous, there are no remaining attributes, or there is no more data to split, in which case a default or majority class is returned.\n",
    "### Args:\n",
    "* **data** : List of lists, where each inner list represents a row of data. The first element of each row is the label ('e' or 'p').\n",
    "* **attributes** : List of integers representing the indices of all available attributes to split the data.\n",
    "* **default** : The default label to use if the dataset is empty.\n",
    "\n",
    "### Returns: \n",
    "* **returns tree** A decision tree represented as a dictionary. The tree is built using the ID3 algorithm, where each node contains either a 'leaf' with a label or a 'node' with an attribute and children representing the possible splits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id3(data, attributes, default): \n",
    "    if not data: \n",
    "        return create_leaf(default)\n",
    "    if is_homogeneous(data):\n",
    "        return create_leaf(data[0][0])\n",
    "    if not attributes:\n",
    "        return create_leaf(majority_class(data))\n",
    "    best_attribute = pick_best_attribute(data, attributes)\n",
    "    values = get_unique_values(data, best_attribute)\n",
    "    children = {}\n",
    "    for value in values:\n",
    "        subset = get_subset(data,best_attribute,value)\n",
    "        remaining_attributes = get_remaining_attributes(attributes, best_attribute)\n",
    "        child = id3(subset, remaining_attributes, majority_class(data))\n",
    "        children[value] = child\n",
    "    return create_node(best_attribute, children)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove_rows_with_missing_values\n",
    "\n",
    "This function filters the input dataset and removes any rows that contain missing values, represented by a '?' in the row. It ensures that the resulting dataset only includes complete rows, which can be important for models or algorithms that don't handle missing values.\n",
    "\n",
    "### Args:\n",
    "* **data** : List of lists, where each inner list represents a row of data. A row may contain missing values represented by a '?'.\n",
    "\n",
    "### Returns: \n",
    "* **returns cleaned_data** A list of rows from the dataset where no missing values ('?') are present.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_rows_with_missing_values(data):\n",
    "    cleaned_data = []\n",
    "    for row in data: \n",
    "        if \"?\" not in row: \n",
    "            cleaned_data.append(row)\n",
    "    return cleaned_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train\n",
    "\n",
    "This function trains a decision tree using the ID3 algorithm. It first cleans the dataset by removing rows with missing values, then selects the attributes for splitting the data, and finally uses the majority class as the default label for empty datasets. The ID3 algorithm is applied to generate the decision tree.\n",
    "\n",
    "### Args:\n",
    "* **training_data** : List of lists, where each inner list represents a row of training data. The first element of each row is the label, and the remaining elements are the attributes.\n",
    "\n",
    "### Returns: \n",
    "* **returns tree** A decision tree generated from the training data using the ID3 algorithm. The tree is represented as a dictionary of nodes and leaves.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(training_data): \n",
    "    cleaned_data = remove_rows_with_missing_values(training_data)\n",
    "    attributes = range(1,len(cleaned_data[0]))\n",
    "    default = majority_class(cleaned_data)\n",
    "    return id3(cleaned_data,attributes, default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = parse_data('agaricus-lepiota.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree = train(data) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## classify_single_observation\n",
    "\n",
    "This function classifies a single observation using a decision tree. It traverses the tree based on the values of the attributes in the observation, following the appropriate branches until it reaches a leaf node, which provides the class label. If the value of the attribute is not found in the tree's children, it returns \"unknown\".\n",
    "\n",
    "### Args:\n",
    "* **tree** : A decision tree represented as a dictionary, where each node contains either a 'leaf' with a label or a 'node' with an attribute and children.\n",
    "* **observation** : A list representing a single observation. Each element corresponds to a value for an attribute.\n",
    "* **labeled** : A boolean indicating whether the observation includes the label as the first element (`True` if labeled, `False` otherwise). Defaults to `True`.\n",
    "\n",
    "### Returns: \n",
    "* **returns label or \"unknown\"** The predicted class label for the observation if the tree can classify it, or \"unknown\" if the observation has an unrecognized value for the attribute.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_single_observation(tree, observation,labeled=True):\n",
    "    if tree['type'] == 'leaf':\n",
    "        return tree['label']\n",
    "    \n",
    "    attribute = tree['attribute']\n",
    "    if labeled:\n",
    "        value = observation[attribute]\n",
    "    else: \n",
    "        value = observation[attribute - 1]\n",
    "    if value in tree['children']:\n",
    "        return classify_single_observation(tree['children'][value], observation, labeled)\n",
    "    return \"unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = {'type': 'leaf', 'label': 'e'}\n",
    "assert classify_single_observation(tree, [0, 1]) == 'e'\n",
    "tree = {'type': 'node', 'attribute': 1, 'children': {1: {'type': 'leaf', 'label': 'p'}}}\n",
    "assert classify_single_observation(tree, [1], labeled=False) == 'p'\n",
    "assert classify_single_observation(tree, [2], labeled=False) == 'unknown'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## classify\n",
    "\n",
    "This function classifies multiple observations using a decision tree. For each observation, it calls the `classify_single_observation` function to traverse the tree and determine the predicted label. The results are stored in a list of predictions.\n",
    "\n",
    "### Args:\n",
    "* **tree** : A decision tree represented as a dictionary, where each node contains either a 'leaf' with a label or a 'node' with an attribute and children.\n",
    "* **observations** : A list of observations, where each observation is a list of attribute values.\n",
    "* **labeled** : A boolean indicating whether the observations include labels as the first element (`True` if labeled, `False` otherwise). Defaults to `True`.\n",
    "\n",
    "### Returns: \n",
    "* **returns predictions** A list of predicted class labels for the given observations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(tree,observations,labeled=True):\n",
    "    predictions = []\n",
    "    for observation in observations:\n",
    "        predictions.append(classify_single_observation(tree, observation,labeled))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = {'type': 'leaf', 'label': 'e'}\n",
    "assert classify(tree, [[0], [1]]) == ['e', 'e']\n",
    "tree = {'type': 'node', 'attribute': 1, 'children': {1: {'type': 'leaf', 'label': 'p'}}}\n",
    "assert classify(tree, [[1], [0]], labeled=False) == ['p', 'unknown']\n",
    "assert classify(tree, [], labeled=True) == []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = remove_rows_with_missing_values(data)\n",
    "predictions = classify(decision_tree, cleaned_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['p', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'p', 'e', 'p', 'p', 'e', 'e', 'p', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'p', 'p', 'p', 'p', 'e', 'e', 'p', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'p', 'p', 'p', 'p', 'e', 'p', 'e', 'e', 'e', 'p', 'p', 'e', 'p', 'e', 'p', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'p', 'e', 'p', 'p', 'p', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'p', 'p', 'p', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'p', 'p', 'p', 'e', 'p', 'p', 'p', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'p', 'p', 'e', 'p', 'e', 'e', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'e', 'p', 'e', 'p', 'e', 'p', 'p', 'e', 'p', 'e', 'p', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'p', 'p', 'p', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'e', 'p', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'p', 'p', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'p', 'p', 'e', 'p', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'p', 'e', 'p', 'p', 'e', 'e', 'p', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'p', 'e', 'p', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'p', 'p', 'e', 'p', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'p', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'p', 'e', 'e', 'p', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'p', 'e', 'p', 'e', 'p', 'e', 'p', 'p', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'p', 'p', 'p', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'p', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'p', 'p', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'p', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'p', 'p', 'p', 'p', 'e', 'e', 'p', 'p', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'p', 'p', 'p', 'p', 'p', 'p', 'e', 'e', 'p', 'p', 'e', 'p', 'p', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'p', 'p', 'p', 'p', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'p', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'p', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'p', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'e', 'p', 'p', 'e', 'p', 'e', 'p', 'p', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'p', 'e', 'e', 'p', 'e', 'p', 'p', 'e', 'p', 'p', 'e', 'e', 'p', 'e', 'p', 'p', 'e', 'e', 'p', 'p', 'p', 'e', 'e', 'e', 'p', 'e', 'p', 'p', 'p', 'e', 'p', 'p', 'p', 'p', 'p', 'e', 'e', 'p', 'e', 'p', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'p', 'e', 'p', 'e', 'p', 'p', 'e', 'e', 'p', 'p', 'e', 'e', 'p', 'e', 'e', 'p', 'p', 'e', 'p', 'p', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'p', 'p', 'p', 'p', 'e', 'p', 'p', 'e', 'p', 'e', 'e', 'p', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'p', 'p', 'e', 'p', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'p', 'e', 'p', 'p', 'p', 'p', 'p', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'e', 'p', 'p', 'e', 'e', 'p', 'p', 'e', 'e', 'p', 'e', 'p', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'e', 'p', 'p', 'p', 'p', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'e', 'p', 'e', 'e', 'p', 'p', 'e', 'p', 'p', 'p', 'e', 'e', 'e', 'p', 'p', 'e', 'p', 'e', 'p', 'p', 'p', 'p', 'p', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'p', 'e', 'p', 'p', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'p', 'e', 'p', 'p', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'p', 'p', 'e', 'p', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'p', 'p', 'e', 'p', 'p', 'p', 'e', 'e', 'p', 'e', 'e', 'p', 'p', 'p', 'p', 'p', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'p', 'p', 'e', 'e', 'p', 'e', 'p', 'p', 'e', 'p', 'p', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'p', 'e', 'e', 'p', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'p', 'p', 'p', 'p', 'e', 'p', 'e', 'p', 'e', 'p', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'p', 'p', 'e', 'p', 'e', 'e', 'p', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'p', 'p', 'e', 'e', 'p', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'e', 'p', 'p', 'p', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'e', 'p', 'p', 'p', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'p', 'p', 'p', 'p', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'p', 'e', 'e', 'p', 'p', 'e', 'p', 'e', 'e', 'e', 'p', 'p', 'e', 'p', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'p', 'e', 'p', 'e', 'p', 'p', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'p', 'e', 'p', 'p', 'e', 'p', 'p', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'p', 'e', 'e', 'p', 'p', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'p', 'p', 'p', 'e', 'e', 'e', 'p', 'p', 'p', 'p', 'p', 'p', 'e', 'p', 'p', 'e', 'p', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'p', 'p', 'p', 'p', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'p', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'p', 'p', 'p', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'p', 'e', 'p', 'e', 'p', 'p', 'p', 'e', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'p', 'e', 'e', 'p', 'p', 'p', 'p', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'p', 'p', 'e', 'p', 'p', 'p', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'p', 'p', 'e', 'e', 'p', 'p', 'p', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'p', 'e', 'e', 'p', 'p', 'p', 'e', 'e', 'e', 'p', 'e', 'p', 'p', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'p', 'e', 'p', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'p', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'p', 'p', 'p', 'p', 'p', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'p', 'e', 'p', 'p', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'p', 'p', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'p', 'p', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'e', 'e', 'p', 'e', 'p', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'p', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'p', 'e', 'e', 'p', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'p', 'p', 'e', 'p', 'e', 'p', 'e', 'p', 'p', 'e', 'e', 'p', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'p', 'p', 'p', 'p', 'e', 'p', 'e', 'p', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'p', 'p', 'p', 'p', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'p', 'p', 'p', 'e', 'p', 'p', 'e', 'p', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'p', 'p', 'e', 'p', 'e', 'p', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'e', 'p', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'p', 'p', 'p', 'p', 'e', 'p', 'p', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'p', 'p', 'e', 'e', 'p', 'e', 'p', 'p', 'p', 'p', 'e', 'e', 'p', 'p', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'p', 'p', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'p', 'p', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'p', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'p', 'p', 'p', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'p', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'p', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'p', 'e', 'p', 'p', 'e', 'e', 'p', 'e', 'p', 'e', 'p', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'p', 'p', 'p', 'p', 'p', 'e', 'p', 'e', 'p', 'p', 'e', 'p', 'e', 'e', 'p', 'p', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'p', 'p', 'p', 'e', 'e', 'e', 'p', 'e', 'p', 'p', 'p', 'e', 'e', 'p', 'p', 'e', 'p', 'p', 'p', 'e', 'p', 'e', 'e', 'p', 'p', 'p', 'e', 'e', 'p', 'e', 'p', 'p', 'e', 'p', 'p', 'p', 'e', 'p', 'e', 'e', 'p', 'p', 'p', 'p', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'p', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'p', 'e', 'p', 'p', 'p', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'p', 'p', 'p', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'p', 'p', 'p', 'p', 'e', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'p', 'p', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'p', 'p', 'p', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'e', 'p', 'p', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'p', 'p', 'p', 'e', 'e', 'p', 'p', 'e', 'p', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'p', 'e', 'e', 'p', 'p', 'p', 'p', 'e', 'e', 'p', 'p', 'e', 'p', 'e', 'e', 'e', 'p', 'p', 'e', 'p', 'p', 'p', 'e', 'e', 'p', 'p', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'p', 'p', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'p', 'e', 'p', 'e', 'e', 'p', 'p', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'p', 'p', 'p', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'p', 'p', 'p', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'p', 'p', 'p', 'e', 'e', 'e', 'p', 'p', 'p', 'p', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'p', 'p', 'e', 'p', 'p', 'p', 'p', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'p', 'e', 'p', 'p', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'p', 'p', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'p', 'e', 'e', 'p', 'e', 'p', 'p', 'p', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'p', 'p', 'p', 'e', 'e', 'e', 'e', 'p', 'p', 'p', 'p', 'p', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'p', 'p', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'p', 'p', 'p', 'e', 'p', 'e', 'p', 'p', 'e', 'p', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'p', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'p', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'p', 'p', 'e', 'p', 'e', 'p', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'p', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'p', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'p', 'e', 'p', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'p', 'p', 'p', 'p', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'p', 'p', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'p', 'p', 'p', 'p', 'p', 'e', 'e', 'p', 'p', 'e', 'p', 'e', 'p', 'p', 'p', 'e', 'p', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'p', 'p', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'p', 'p', 'p', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'p', 'p', 'e', 'p', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'e', 'p', 'e', 'p', 'e', 'p', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'p', 'e', 'p', 'e', 'p', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'p', 'p', 'p', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'p', 'e', 'p', 'e', 'e', 'p', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'p', 'e', 'p', 'e', 'p', 'e', 'p', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'e', 'p', 'e', 'e', 'p', 'p', 'e', 'e', 'p', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'p', 'p', 'p', 'p', 'p', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'p', 'e', 'p', 'p', 'e', 'p', 'e', 'p', 'p', 'e', 'e', 'p', 'p', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'p', 'p', 'e', 'p', 'p', 'p', 'e', 'p', 'p', 'p', 'e', 'p', 'p', 'e', 'e', 'p', 'p', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'p', 'p', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'p', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'p', 'p', 'p', 'p', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'p', 'p', 'p', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'p', 'p', 'e', 'p', 'p', 'e', 'e', 'p', 'p', 'p', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'p', 'e', 'p', 'p', 'e', 'p', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'p', 'p', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'p', 'e', 'p', 'e', 'p', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'p', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'p', 'p', 'p', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'p', 'p', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'p', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'p', 'p', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'p', 'p', 'p', 'p', 'p', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'p', 'e', 'p', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'p', 'e', 'p', 'p', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'p', 'e', 'p', 'p', 'p', 'p', 'p', 'e', 'e', 'p', 'e', 'p', 'e', 'p', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'p', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'p', 'p', 'p', 'p', 'p', 'e', 'p', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'p', 'p', 'p', 'e', 'e', 'p', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'p', 'p', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'p', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'p', 'p', 'p', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'p', 'e', 'p', 'p', 'p', 'p', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'p', 'e', 'p', 'p', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'p', 'e', 'p', 'p', 'p', 'e', 'p', 'p', 'e', 'p', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'e', 'p', 'p', 'e', 'p', 'e', 'p', 'p', 'p', 'e', 'e', 'e', 'p', 'p', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'p', 'e', 'p', 'e', 'p', 'p', 'e', 'e', 'p', 'e', 'p', 'p', 'p', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'p', 'p', 'e', 'p', 'e', 'p', 'e', 'p', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'p', 'p', 'p', 'e', 'e', 'p', 'p', 'e', 'p', 'p', 'p', 'p', 'p', 'p', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'p', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'p', 'e', 'p', 'e', 'p', 'e', 'e', 'p', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'p', 'p', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'p', 'p', 'e', 'e', 'e', 'p', 'p', 'e', 'p', 'p', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'e', 'p', 'p', 'p', 'p', 'p', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'p', 'e', 'p', 'p', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'p', 'e', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'e', 'p', 'p', 'p', 'e', 'p', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'p', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'p', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'e', 'p', 'e', 'p', 'p', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'p', 'p', 'e', 'p', 'p', 'p', 'e', 'p', 'e', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'p', 'e', 'e', 'e', 'e', 'p', 'e', 'e', 'p', 'p', 'p', 'e', 'p', 'p', 'e', 'p', 'p', 'p', 'p', 'e', 'p', 'p', 'e', 'p', 'e', 'e', 'p', 'e', 'e', 'p', 'p', 'p', 'e', 'p', 'p', 'e', 'p', 'p', 'e', 'e', 'p', 'e', 'e', 'p', 'p', 'p', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'p', 'e', 'p', 'e', 'p', 'e', 'e', 'e', 'p', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'p', 'e', 'e', 'e', 'p', 'p']\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluate\n",
    "\n",
    "This function evaluates the performance of a classifier by comparing the predicted labels to the actual labels in the labeled data. It calculates the error rate by determining the proportion of incorrect predictions.\n",
    "\n",
    "### Args:\n",
    "* **predicted_labels** : A list of predicted class labels.\n",
    "* **labeled_data** : A list of lists, where each inner list represents an observation. The first element of each observation is the actual label.\n",
    "\n",
    "### Returns: \n",
    "* **returns error_rate** The error rate, calculated as the number of incorrect predictions divided by the total number of observations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(predicted_labels, labeled_data):\n",
    "    errors = 0\n",
    "    n = len(labeled_data)\n",
    "    for i in range(n):\n",
    "        actual_label = labeled_data[i][0]\n",
    "        predicted_label = predicted_labels[i]\n",
    "        if predicted_label != actual_label:\n",
    "            errors += 1\n",
    "    error_rate = errors / n\n",
    "    return error_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "error_rate = evaluate(predictions,cleaned_data)\n",
    "print(error_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train_and_evaluate\n",
    "\n",
    "This function trains a model using the provided training function, then classifies the test data using the provided classification function, and finally evaluates the model's performance using the provided evaluation function. It returns the error rate on the test data.\n",
    "\n",
    "### Args:\n",
    "* **train_fn** : A function used to train the model, taking the training data as input.\n",
    "* **classify_fn** : A function used to classify observations, taking the model and the test data as inputs.\n",
    "* **evaluate_fn** : A function used to evaluate the model's performance, taking the predicted labels and labeled test data as inputs.\n",
    "* **train_fold** : A list of lists representing the training data.\n",
    "* **test_fold** : A list of lists representing the test data. The first element of each observation is the actual label.\n",
    "\n",
    "### Returns: \n",
    "* **returns test_error** The error rate of the model on the test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(train_fn, classify_fn, evaluate_fn, train_fold, test_fold):\n",
    "    model = train_fn(train_fold)\n",
    "    predicted_test_labels = classify_fn(model, test_fold, labeled=True)\n",
    "    test_error = evaluate_fn(predicted_test_labels, test_fold)\n",
    "    return test_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate_and_print_mean\n",
    "\n",
    "This function calculates the mean test error rate across multiple folds and prints the result with four decimal places of precision.\n",
    "\n",
    "### Args:\n",
    "* **total_test_error_rate** : The sum of test error rates from all folds.\n",
    "* **num_folds** : The number of folds used in the evaluation.\n",
    "\n",
    "### Returns:\n",
    "* **None** : This function does not return any value. It prints the mean test error rate to the console.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_and_print_mean(total_test_error_rate, num_folds):\n",
    "    mean_test_error_rate = total_test_error_rate / num_folds\n",
    "    print(f\"Mean = {mean_test_error_rate:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cross_validate\n",
    "\n",
    "This function performs cross-validation on the provided dataset by splitting the data into 10 folds. It trains and evaluates a model for each pair of consecutive folds, printing the error rate for each pair. It also calculates and prints the mean test error rate across all folds.\n",
    "\n",
    "### Args:\n",
    "* **data** : List of lists, where each inner list represents an observation in the dataset. The first element of each observation is the label.\n",
    "* **train_fn** : A function used to train the model, taking the training data as input.\n",
    "* **classify_fn** : A function used to classify observations, taking the model and the test data as inputs.\n",
    "* **evaluate_fn** : A function used to evaluate the model's performance, taking the predicted labels and labeled test data as inputs.\n",
    "\n",
    "### Returns:\n",
    "* **None** : This function does not return any value. It prints the error rates for each pair of folds and the mean test error rate across all folds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(data, train_fn, classify_fn, evaluate_fn):    \n",
    "    total_test_error_rate = 0\n",
    "    folds = create_folds(data, 10)\n",
    "    print(\"Train   Test\")\n",
    "    for i in range(0, 10, 2):\n",
    "        fold_train = folds[i]\n",
    "        fold_test = folds[i + 1]\n",
    "        test_error1 = train_and_evaluate(train_fn, classify_fn, evaluate_fn, fold_train, fold_test)\n",
    "        print(f\"Fold {i + 1} -> Fold {i + 2} error rate: {test_error1:.4f}\")\n",
    "        test_error2 = train_and_evaluate(train_fn, classify_fn, evaluate_fn, fold_test, fold_train)\n",
    "        print(f\"Fold {i + 2} -> Fold {i + 1} error rate: {test_error2:.4f}\")\n",
    "        total_test_error_rate += test_error1 + test_error2\n",
    "    calculate_and_print_mean(total_test_error_rate, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train   Test\n",
      "Fold 1 -> Fold 2 error rate: 0.0035\n",
      "Fold 2 -> Fold 1 error rate: 0.0088\n",
      "Fold 3 -> Fold 4 error rate: 0.0088\n",
      "Fold 4 -> Fold 3 error rate: 0.0018\n",
      "Fold 5 -> Fold 6 error rate: 0.0035\n",
      "Fold 6 -> Fold 5 error rate: 0.0000\n",
      "Fold 7 -> Fold 8 error rate: 0.0035\n",
      "Fold 8 -> Fold 7 error rate: 0.0053\n",
      "Fold 9 -> Fold 10 error rate: 0.0035\n",
      "Fold 10 -> Fold 9 error rate: 0.0000\n",
      "Mean = 0.0039\n"
     ]
    }
   ],
   "source": [
    "cross_validate(cleaned_data,train,classify,evaluate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pretty_print_tree\n",
    "\n",
    "This function prints a decision tree in a readable, indented format. It recursively traverses the tree, printing decision nodes and their corresponding attribute splits, as well as leaf nodes and their classification results. Each level of the tree is indented to visually represent the structure.\n",
    "\n",
    "### Args:\n",
    "* **tree** : A decision tree represented as a dictionary. Each node contains either a 'leaf' with a label or a 'node' with an attribute and children representing further splits.\n",
    "* **indent** : A string used to control the indentation for the current node level. Defaults to an empty string.\n",
    "* **parent_indent** : A string used to control the indentation for the parent node. It helps in formatting the child nodes properly. Defaults to an empty string.\n",
    "\n",
    "### Returns:\n",
    "* **None** : This function does not return any value. It prints the tree in a structured and readable format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_tree(tree,indent=\"\", parent_indent=\"\"):\n",
    "    if tree['type'] == 'leaf':\n",
    "        print(f\"{indent}[Leaf Node] Results: {tree['label']}\")\n",
    "    else:\n",
    "        print(f\"{indent}[Decision Node] Attribute: {tree['attribute']}\")\n",
    "        for value, subtree in tree['children'].items():\n",
    "            print(f\"{parent_indent}|-- Value: {value} -->\", end=\" \") \n",
    "            pretty_print_tree(subtree, indent=\"\", parent_indent=parent_indent + \"     \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Decision Node] Attribute: 5\n",
      "|-- Value: a --> [Leaf Node] Results: e\n",
      "|-- Value: f --> [Leaf Node] Results: p\n",
      "|-- Value: m --> [Leaf Node] Results: p\n",
      "|-- Value: n --> [Decision Node] Attribute: 20\n",
      "     |-- Value: r --> [Leaf Node] Results: p\n",
      "     |-- Value: k --> [Leaf Node] Results: e\n",
      "     |-- Value: n --> [Leaf Node] Results: e\n",
      "     |-- Value: w --> [Decision Node] Attribute: 3\n",
      "          |-- Value: g --> [Leaf Node] Results: e\n",
      "          |-- Value: y --> [Leaf Node] Results: p\n",
      "          |-- Value: n --> [Leaf Node] Results: e\n",
      "          |-- Value: c --> [Leaf Node] Results: e\n",
      "          |-- Value: p --> [Leaf Node] Results: e\n",
      "          |-- Value: w --> [Leaf Node] Results: p\n",
      "|-- Value: c --> [Leaf Node] Results: p\n",
      "|-- Value: p --> [Leaf Node] Results: p\n",
      "|-- Value: l --> [Leaf Node] Results: e\n"
     ]
    }
   ],
   "source": [
    "pretty_print_tree(decision_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attribute': 5,\n",
      " 'children': {'a': {'label': 'e', 'type': 'leaf'},\n",
      "              'c': {'label': 'p', 'type': 'leaf'},\n",
      "              'f': {'label': 'p', 'type': 'leaf'},\n",
      "              'l': {'label': 'e', 'type': 'leaf'},\n",
      "              'm': {'label': 'p', 'type': 'leaf'},\n",
      "              'n': {'attribute': 20,\n",
      "                    'children': {'k': {'label': 'e', 'type': 'leaf'},\n",
      "                                 'n': {'label': 'e', 'type': 'leaf'},\n",
      "                                 'r': {'label': 'p', 'type': 'leaf'},\n",
      "                                 'w': {'attribute': 3,\n",
      "                                       'children': {'c': {'label': 'e',\n",
      "                                                          'type': 'leaf'},\n",
      "                                                    'g': {'label': 'e',\n",
      "                                                          'type': 'leaf'},\n",
      "                                                    'n': {'label': 'e',\n",
      "                                                          'type': 'leaf'},\n",
      "                                                    'p': {'label': 'e',\n",
      "                                                          'type': 'leaf'},\n",
      "                                                    'w': {'label': 'p',\n",
      "                                                          'type': 'leaf'},\n",
      "                                                    'y': {'label': 'p',\n",
      "                                                          'type': 'leaf'}},\n",
      "                                       'type': 'node'}},\n",
      "                    'type': 'node'},\n",
      "              'p': {'label': 'p', 'type': 'leaf'}},\n",
      " 'type': 'node'}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(decision_tree)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "en605645",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "81px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

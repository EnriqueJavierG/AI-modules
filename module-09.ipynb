{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(file_name: str) -> list[list]:\n",
    "    data = []\n",
    "    file = open(file_name, \"r\")\n",
    "    for line in file:\n",
    "        datum = line.rstrip().split(\",\")\n",
    "        data.append(datum)\n",
    "    random.shuffle(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use this function to create 10 folds for 5x2 cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folds(xs: list, n: int) -> list[list[list]]:\n",
    "    k, m = divmod(len(xs), n)\n",
    "    # be careful of generators...\n",
    "    return list(xs[i * k + min(i, m):(i + 1) * k + min(i + 1, m)] for i in range(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = [\n",
    "    ['p', 'x', 's', 'n', 't', 'p', 'f', 'c', 'n', 'k', 'e', 'e', 's', 's', 'w', 'w', 'p', 'w', 'o', 'p', 'k', 's', 'u'],\n",
    "    ['e', 'x', 's', 'y', 't', 'a', 'f', 'c', 'b', 'k', 'e', 'c', 's', 's', 'w', 'w', 'p', 'w', 'o', 'p', 'n', 'n', 'g'],\n",
    "    ['e', 'b', 's', 'w', 't', 'l', 'f', 'c', 'b', 'n', 'e', 'c', 's', 's', 'w', 'w', 'p', 'w', 'o', 'p', 'n', 'n', 'm'],\n",
    "    ['p', 'x', 'y', 'w', 't', 'p', 'f', 'c', 'n', 'n', 'e', 'e', 's', 's', 'w', 'w', 'p', 'w', 'o', 'p', 'k', 's', 'u'],\n",
    "    ['e', 'x', 's', 'g', 'f', 'n', 'f', 'w', 'b', 'k', 't', 'e', 's', 's', 'w', 'w', 'p', 'w', 'o', 'e', 'n', 'a', 'g'],\n",
    "    ['e', 'x', 'y', 'y', 't', 'a', 'f', 'c', 'b', 'n', 'e', 'c', 's', 's', 'w', 'w', 'p', 'w', 'o', 'p', 'k', 'n', 'g'],\n",
    "    ['e', 'b', 's', 'w', 't', 'a', 'f', 'c', 'b', 'g', 'e', 'c', 's', 's', 'w', 'w', 'p', 'w', 'o', 'p', 'k', 'n', 'm'],\n",
    "    ['e', 'b', 'y', 'w', 't', 'l', 'f', 'c', 'b', 'n', 'e', 'c', 's', 's', 'w', 'w', 'p', 'w', 'o', 'p', 'n', 's', 'm'],\n",
    "    ['p', 'x', 'y', 'w', 't', 'p', 'f', 'c', 'n', 'p', 'e', 'e', 's', 's', 'w', 'w', 'p', 'w', 'o', 'p', 'k', 'v', 'g'],\n",
    "    ['e', 'b', 's', 'y', 't', 'a', 'f', 'c', 'b', 'g', 'e', 'c', 's', 's', 'w', 'w', 'p', 'w', 'o', 'p', 'k', 's', 'm']\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initialize_dictionary_with_defaultdict\n",
    "\n",
    "This function initializes a dictionary to hold feature counts using nested `defaultdict` structures for each feature index. It sets up each feature index to map to a dictionary, facilitating easy updates for feature value counts.\n",
    "\n",
    "### Args:\n",
    "* **dictionary** : A dictionary intended to store feature counts, where each feature index maps to a nested `defaultdict`.\n",
    "* **num_features** : An integer representing the number of features in each observation.\n",
    "\n",
    "### Returns:\n",
    "* **dictionary** : The input dictionary, modified to include each feature index as a key, mapped to a nested `defaultdict` that will store feature value counts for each label.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_dictionary_with_defaultdict(dictionary, num_features):\n",
    "    for i in range(1, num_features + 1):\n",
    "        dictionary[i] = defaultdict(dict)\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dict = initialize_dictionary_with_defaultdict({}, 3)\n",
    "assert all(isinstance(feature_dict[i], defaultdict) for i in range(1, 4))\n",
    "assert len(initialize_dictionary_with_defaultdict({}, 5)) == 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## count_feature_occurrences\n",
    "\n",
    "This function counts the occurrences of each feature value given a label across all observations in the training data. It updates the feature counts dictionary with these values, which are used for conditional probability calculations in a Naive Bayes Classifier.\n",
    "\n",
    "### Args:\n",
    "* **training_data** : A list of lists where each inner list represents an observation. The first element in each row is the label, followed by feature values.\n",
    "* **feature_counts** : A dictionary of dictionaries where each feature index maps to a dictionary of feature values and their counts for each label. This dictionary is updated in place.\n",
    "* **num_features** : An integer representing the number of features in each observation.\n",
    "\n",
    "### Returns:\n",
    "* **feature_counts** : A dictionary of dictionaries updated with the counts of each feature value for each label, where each feature index maps to a dictionary of feature values and their respective label counts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_feature_occurrences(training_data, feature_counts, num_features):\n",
    "    for row in training_data:\n",
    "        label = row[0]\n",
    "        for i in range(1, num_features + 1):\n",
    "            feature_value = row[i]\n",
    "            if label not in feature_counts[i][feature_value]:\n",
    "                feature_counts[i][feature_value][label] = 0\n",
    "            feature_counts[i][feature_value][label] += 1\n",
    "    return feature_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = len(test_data[0]) - 1\n",
    "feature_counts = defaultdict(lambda: defaultdict(dict))\n",
    "result_counts = count_feature_occurrences(test_data, feature_counts, num_features)\n",
    "assert result_counts[1]['x']['p'] == 3\n",
    "assert result_counts[2]['s']['e']== 5\n",
    "assert result_counts[2].get('z', {}).get('p', 0) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get_unique_values\n",
    "\n",
    "This function extracts the unique values for a specified feature index across all observations in the training data. It is useful for setting up data structures or applying smoothing for a Naive Bayes Classifier.\n",
    "\n",
    "### Args:\n",
    "* **training_data** : A list of lists where each inner list represents an observation.\n",
    "* **feature_index** : An integer specifying the index of the feature for which unique values are needed.\n",
    "\n",
    "### Returns:\n",
    "* **unique_values** : A set containing all unique values for the specified feature index in the training data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_values(training_data, feature_index):\n",
    "    unique_values = set()\n",
    "    for row in training_data:\n",
    "        unique_values.add(row[feature_index])\n",
    "    return unique_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert get_unique_values([['A', 1], ['B', 2], ['A', 3]], 1) == {1, 2, 3}\n",
    "assert get_unique_values([['A', 1], ['B', 1], ['A', 2]], 1) == {1, 2}\n",
    "assert get_unique_values([['A', 1], ['B', 1], ['A', 1]], 1) == {1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## apply_smoothing\n",
    "\n",
    "This function applies Laplace smoothing to the feature counts, ensuring that each feature value has an initial count for each label, even if it does not appear in the training data. This helps avoid zero probabilities in the Naive Bayes calculations.\n",
    "\n",
    "### Args:\n",
    "* **training_data** : A list of lists where each inner list represents an observation. The first element in each row is the label, followed by feature values.\n",
    "* **feature_counts** : A dictionary of dictionaries where each feature index maps to a dictionary of feature values and their counts for each label.\n",
    "* **unique_labels** : A set of unique labels present in the training data.\n",
    "* **num_features** : An integer representing the number of features in each observation.\n",
    "\n",
    "### Returns:\n",
    "* This function does not return a value. It modifies `feature_counts` in place by adding a count of 1 for each feature value and label combination that does not already exist.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_smoothing(training_data, feature_counts, unique_labels, num_features):\n",
    "    for i in range(1, num_features + 1):\n",
    "        unique_values = get_unique_values(training_data, i)\n",
    "        for value in unique_values:\n",
    "            for label in unique_labels:\n",
    "                if label not in feature_counts[i][value]:\n",
    "                    feature_counts[i][value][label] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = len(test_data[0]) - 1\n",
    "feature_counts = defaultdict(lambda: defaultdict(dict))\n",
    "unique_labels = {'p', 'e'}\n",
    "apply_smoothing(test_data, feature_counts, unique_labels, num_features)\n",
    "assert feature_counts[1]['x']['p'] == 1\n",
    "assert feature_counts[2]['s']['e'] == 1 and feature_counts[2]['s']['p'] == 1\n",
    "assert feature_counts[3]['y'].get('e', 1) == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get_unique_labels\n",
    "\n",
    "This function extracts the unique labels from the training data, which is useful for initializing data structures or applying smoothing in a Naive Bayes Classifier.\n",
    "\n",
    "### Args:\n",
    "* **training_data** : A list of lists where each inner list represents an observation. The first element in each row is the label.\n",
    "\n",
    "### Returns:\n",
    "* **unique_labels** : A set containing all unique labels in the training data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_labels(training_data):\n",
    "    unique_labels = set()\n",
    "    for row in training_data:\n",
    "        unique_labels.add(row[0])\n",
    "    return unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert get_unique_labels([['A', 1], ['B', 2], ['A', 3]]) == {'A', 'B'} \n",
    "assert get_unique_labels([['A', 1], ['A', 2]]) == {'A'}\n",
    "assert len(get_unique_labels([['A'], ['B'], ['B']])) == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initialize_feature_counts\n",
    "\n",
    "This function initializes the feature counts dictionary for each feature in the training data. It optionally applies Laplace smoothing to handle unseen feature values for each label.\n",
    "\n",
    "### Args:\n",
    "* **training_data** : A list of lists where each inner list represents an observation. The first element in each row is the label, followed by feature values.\n",
    "* **num_features** : An integer representing the number of features in each observation.\n",
    "* **smoothing** : A boolean flag indicating whether to apply Laplace smoothing to the feature counts.\n",
    "\n",
    "### Returns:\n",
    "* **feature_counts** : A dictionary of dictionaries where each feature index maps to a dictionary of feature values, which are initialized for each label.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_feature_counts(training_data, num_features, smoothing):\n",
    "    feature_counts = defaultdict(dict)\n",
    "    feature_counts = initialize_dictionary_with_defaultdict(feature_counts, num_features)\n",
    "    if smoothing:\n",
    "        unique_labels = get_unique_labels(training_data)\n",
    "        apply_smoothing(training_data, feature_counts, unique_labels, num_features)\n",
    "    return feature_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(initialize_feature_counts(test_data, len(test_data[0]) - 1, smoothing=True), defaultdict)\n",
    "feature_counts = initialize_feature_counts(test_data, len(test_data[0]) - 1, smoothing=True)\n",
    "assert len(feature_counts) == len(test_data[0]) - 1\n",
    "assert all(isinstance(feature_counts[i], dict) for i in range(1, len(test_data[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## count_label_occurrences\n",
    "\n",
    "This function counts the occurrences of each label in the training data, helping to determine the prior probability of each label for a Naive Bayes Classifier.\n",
    "\n",
    "### Args:\n",
    "* **training_data** : A list of lists where each inner list represents an observation. The first element in each row is the label.\n",
    "\n",
    "### Returns:\n",
    "* **label_counts** : A dictionary where each key is a label, and the corresponding value is the count of that label in the training data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_label_occurrences(training_data):\n",
    "    label_counts = defaultdict(int)\n",
    "    for row in training_data:\n",
    "        label_counts[row[0]] += 1\n",
    "    return label_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert count_label_occurrences(test_data)['p'] == 3\n",
    "assert set(count_label_occurrences(test_data).keys()) == {'p', 'e'}\n",
    "assert count_label_occurrences(test_data).get('x', 0) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## count_occurrences\n",
    "\n",
    "This function counts the occurrences of labels and feature values within the training data, which are essential for calculating probabilities in the Naive Bayes Classifier. It initializes feature counts and counts occurrences for each feature value given a label.\n",
    "\n",
    "### Args:\n",
    "* **training_data** : A list of lists where each inner list represents an observation. The first element in each row is the label, followed by feature values.\n",
    "* **num_features** : An integer representing the number of features in each observation.\n",
    "* **smoothing** : A boolean flag indicating whether to apply Laplace smoothing when initializing feature counts.\n",
    "\n",
    "### Returns:\n",
    "* **label_counts** : A dictionary containing the count of each label in the training data.\n",
    "* **feature_counts** : A dictionary of dictionaries where each feature index maps to a dictionary of feature values and their counts for each label.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_occurrences(training_data, num_features, smoothing):\n",
    "    label_counts = count_label_occurrences(training_data)\n",
    "    feature_counts = initialize_feature_counts(training_data, num_features, smoothing)\n",
    "    feature_counts = count_feature_occurrences(training_data, feature_counts, num_features)\n",
    "    return label_counts, feature_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train\n",
    "\n",
    "This function trains a Naive Bayes Classifier (NBC) on a given dataset, calculating probabilities for each label and feature value. It supports optional Laplace smoothing to handle unseen feature values.\n",
    "\n",
    "### Args:\n",
    "* **training_data** : A list of lists where each inner list represents an observation. The first element in each row is the label, and the subsequent elements are feature values.\n",
    "* **smoothing** : A boolean flag indicating whether to apply Laplace smoothing. Default is `True`.\n",
    "\n",
    "### Returns:\n",
    "* **classifier** : A dictionary representing the trained Naive Bayes Classifier. For each label, it contains:\n",
    "  - **'probability'** : The prior probability of the label.\n",
    "  - **'features'** : A dictionary where each feature index maps to a dictionary of feature values and their respective conditional probabilities given the label.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(training_data, smoothing=True):\n",
    "    feature_counts = defaultdict(dict)\n",
    "    num_features = len(training_data[0]) - 1\n",
    "    label_counts, feature_counts = count_occurrences(training_data, num_features, smoothing)\n",
    "    classifier = {}\n",
    "    total_samples = sum(label_counts.values())\n",
    "    for label in label_counts:\n",
    "        label_prob = label_counts[label] / total_samples\n",
    "        classifier[label] = {'probability': label_prob, 'features': {}}\n",
    "        for feature_index in range(1, num_features + 1):\n",
    "            classifier[label]['features'][feature_index] = {}\n",
    "            feature_values = feature_counts[feature_index]\n",
    "            for feature_value, label_count in feature_values.items():\n",
    "                count = label_count.get(label, 1) if smoothing else label_count.get(label, 0)\n",
    "                smoothed_total = label_counts[label] + len(feature_values) if smoothing else label_counts[label]\n",
    "                classifier[label]['features'][feature_index][feature_value] = count / smoothed_total\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove_rows_with_missing_values\n",
    "\n",
    "This function removes rows containing missing values (represented by `\"?\"`) from the dataset.\n",
    "\n",
    "### Args:\n",
    "* **data** : A list of lists, where each inner list represents a row of data. Each row may contain one or more values, with `\"?\"` representing a missing value.\n",
    "\n",
    "### Returns:\n",
    "* **cleaned_data** : A list of lists containing only rows without any missing values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_rows_with_missing_values(data):\n",
    "    cleaned_data = []\n",
    "    for row in data: \n",
    "        if \"?\" not in row: \n",
    "            cleaned_data.append(row)\n",
    "    return cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = parse_data(\"agaricus-lepiota-1.data\")\n",
    "cleaned_data = remove_rows_with_missing_values(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_classifier = train(cleaned_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'e': {'features': {1: {'b': 0.0746994848311391,\n",
      "                        'c': 0.00028620492272467084,\n",
      "                        'f': 0.41814539210074414,\n",
      "                        'k': 0.006010303377218088,\n",
      "                        's': 0.009444762449914138,\n",
      "                        'x': 0.49141385231825985},\n",
      "                    2: {'f': 0.40578465063001146,\n",
      "                        'g': 0.000286368843069874,\n",
      "                        's': 0.20418098510882016,\n",
      "                        'y': 0.3897479954180985},\n",
      "                    3: {'b': 0.0002860411899313501,\n",
      "                        'c': 0.009439359267734555,\n",
      "                        'e': 0.16504576659038903,\n",
      "                        'g': 0.2542906178489702,\n",
      "                        'n': 0.2931922196796339,\n",
      "                        'p': 0.002574370709382151,\n",
      "                        'w': 0.1604691075514874,\n",
      "                        'y': 0.1147025171624714},\n",
      "                    4: {'f': 0.266189111747851, 't': 0.733810888252149},\n",
      "                    5: {'a': 0.11473533619456366,\n",
      "                        'c': 0.0002861230329041488,\n",
      "                        'f': 0.0002861230329041488,\n",
      "                        'l': 0.11473533619456366,\n",
      "                        'm': 0.0002861230329041488,\n",
      "                        'n': 0.7693848354792561,\n",
      "                        'p': 0.0002861230329041488},\n",
      "                    6: {'a': 0.00028653295128939826, 'f': 0.9997134670487106},\n",
      "                    7: {'c': 0.7383954154727793, 'w': 0.26160458452722063},\n",
      "                    8: {'b': 0.930945558739255, 'n': 0.06905444126074499},\n",
      "                    9: {'g': 0.04375178724621104,\n",
      "                        'h': 0.05519016299685445,\n",
      "                        'k': 0.0986559908492994,\n",
      "                        'n': 0.2496425507577924,\n",
      "                        'p': 0.2130397483557335,\n",
      "                        'r': 0.00028595939376608524,\n",
      "                        'u': 0.1238204175007149,\n",
      "                        'w': 0.21532742350586218,\n",
      "                        'y': 0.00028595939376608524},\n",
      "                    10: {'e': 0.2570200573065903, 't': 0.7429799426934097},\n",
      "                    11: {'b': 0.550114547537228,\n",
      "                         'c': 0.14690721649484537,\n",
      "                         'e': 0.24770904925544102,\n",
      "                         'r': 0.05526918671248568},\n",
      "                    12: {'f': 0.11712485681557847,\n",
      "                         'k': 0.000286368843069874,\n",
      "                         's': 0.8777205040091638,\n",
      "                         'y': 0.004868270332187858},\n",
      "                    13: {'f': 0.11712485681557847,\n",
      "                         'k': 0.000286368843069874,\n",
      "                         's': 0.822737686139748,\n",
      "                         'y': 0.05985108820160367},\n",
      "                    14: {'b': 0.0002861230329041488,\n",
      "                         'c': 0.0002861230329041488,\n",
      "                         'g': 0.16509298998569386,\n",
      "                         'n': 0.004864091559370529,\n",
      "                         'p': 0.16509298998569386,\n",
      "                         'w': 0.6640915593705293,\n",
      "                         'y': 0.0002861230329041488},\n",
      "                    15: {'b': 0.0002861230329041488,\n",
      "                         'c': 0.0002861230329041488,\n",
      "                         'g': 0.16509298998569386,\n",
      "                         'n': 0.01859799713876967,\n",
      "                         'p': 0.16509298998569386,\n",
      "                         'w': 0.6503576537911302,\n",
      "                         'y': 0.0002861230329041488},\n",
      "                    16: {'p': 1.0},\n",
      "                    17: {'w': 0.9997134670487106, 'y': 0.00028653295128939826},\n",
      "                    18: {'n': 0.0002864508736751647,\n",
      "                         'o': 0.9856774563162418,\n",
      "                         't': 0.01403609281008307},\n",
      "                    19: {'e': 0.23396334478808706,\n",
      "                         'l': 0.000286368843069874,\n",
      "                         'n': 0.000286368843069874,\n",
      "                         'p': 0.7654639175257731},\n",
      "                    20: {'h': 0.00028620492272467084,\n",
      "                         'k': 0.47195191757298227,\n",
      "                         'n': 0.48568975386376645,\n",
      "                         'r': 0.00028620492272467084,\n",
      "                         'u': 0.014024041213508873,\n",
      "                         'w': 0.027761877504293073},\n",
      "                    21: {'a': 0.11018889524899829,\n",
      "                         'c': 0.00028620492272467084,\n",
      "                         'n': 0.07355466514024041,\n",
      "                         's': 0.21093302804808242,\n",
      "                         'v': 0.30709788208357186,\n",
      "                         'y': 0.2979393245563824},\n",
      "                    22: {'d': 0.5246136233543217,\n",
      "                         'g': 0.32083571837435604,\n",
      "                         'l': 0.014024041213508873,\n",
      "                         'm': 0.07355466514024041,\n",
      "                         'p': 0.03921007441327991,\n",
      "                         'u': 0.027761877504293073}},\n",
      "       'probability': 0.6180014174344437},\n",
      " 'p': {'features': {1: {'b': 0.018963922294172063,\n",
      "                        'c': 0.002312673450508788,\n",
      "                        'f': 0.45004625346901017,\n",
      "                        'k': 0.00786308973172988,\n",
      "                        's': 0.00046253469010175765,\n",
      "                        'x': 0.5203515263644773},\n",
      "                    2: {'f': 0.3449074074074074,\n",
      "                        'g': 0.0023148148148148147,\n",
      "                        's': 0.25416666666666665,\n",
      "                        'y': 0.39861111111111114},\n",
      "                    3: {'b': 0.05591497227356747,\n",
      "                        'c': 0.006007393715341959,\n",
      "                        'e': 0.006007393715341959,\n",
      "                        'g': 0.37384473197781887,\n",
      "                        'n': 0.06515711645101664,\n",
      "                        'p': 0.0411275415896488,\n",
      "                        'w': 0.14833641404805914,\n",
      "                        'y': 0.3036044362292052},\n",
      "                    4: {'f': 0.7103799814643188, 't': 0.2896200185356812},\n",
      "                    5: {'a': 0.0004623208506703652,\n",
      "                        'c': 0.0892279241793805,\n",
      "                        'f': 0.7327785483125289,\n",
      "                        'l': 0.0004623208506703652,\n",
      "                        'm': 0.017105871474803514,\n",
      "                        'n': 0.041146555709662504,\n",
      "                        'p': 0.11881645862228386},\n",
      "                    6: {'a': 0.008804448563484708, 'f': 0.9911955514365153},\n",
      "                    7: {'c': 0.9476367006487488, 'w': 0.052363299351251155},\n",
      "                    8: {'b': 0.7845227062094532, 'n': 0.2154772937905468},\n",
      "                    9: {'g': 0.23325635103926096,\n",
      "                        'h': 0.2443418013856813,\n",
      "                        'k': 0.03002309468822171,\n",
      "                        'n': 0.052193995381062355,\n",
      "                        'p': 0.29607390300230946,\n",
      "                        'r': 0.011547344110854504,\n",
      "                        'u': 0.022632794457274827,\n",
      "                        'w': 0.09930715935334873,\n",
      "                        'y': 0.010623556581986143},\n",
      "                    10: {'e': 0.866079703429101, 't': 0.133920296570899},\n",
      "                    11: {'b': 0.8597222222222223,\n",
      "                         'c': 0.020833333333333332,\n",
      "                         'e': 0.11898148148148148,\n",
      "                         'r': 0.000462962962962963},\n",
      "                    12: {'f': 0.06712962962962964,\n",
      "                         'k': 0.6171296296296296,\n",
      "                         's': 0.31157407407407406,\n",
      "                         'y': 0.004166666666666667},\n",
      "                    13: {'f': 0.06712962962962964,\n",
      "                         'k': 0.600462962962963,\n",
      "                         's': 0.31157407407407406,\n",
      "                         'y': 0.020833333333333332},\n",
      "                    14: {'b': 0.20018492834026816,\n",
      "                         'c': 0.017105871474803514,\n",
      "                         'g': 0.0004623208506703652,\n",
      "                         'n': 0.20018492834026816,\n",
      "                         'p': 0.20018492834026816,\n",
      "                         'w': 0.3777161349976884,\n",
      "                         'y': 0.004160887656033287},\n",
      "                    15: {'b': 0.20018492834026816,\n",
      "                         'c': 0.017105871474803514,\n",
      "                         'g': 0.0004623208506703652,\n",
      "                         'n': 0.20018492834026816,\n",
      "                         'p': 0.20018492834026816,\n",
      "                         'w': 0.3777161349976884,\n",
      "                         'y': 0.004160887656033287},\n",
      "                    16: {'p': 1.0},\n",
      "                    17: {'w': 0.9958294717330862, 'y': 0.004170528266913809},\n",
      "                    18: {'n': 0.01713756368689208,\n",
      "                         'o': 0.9490504863362668,\n",
      "                         't': 0.03381194997684113},\n",
      "                    19: {'e': 0.004166666666666667,\n",
      "                         'l': 0.600462962962963,\n",
      "                         'n': 0.01712962962962963,\n",
      "                         'p': 0.37824074074074077},\n",
      "                    20: {'h': 0.7331174838112858,\n",
      "                         'k': 0.10407030527289547,\n",
      "                         'n': 0.10407030527289547,\n",
      "                         'r': 0.033765032377428304,\n",
      "                         'u': 0.00046253469010175765,\n",
      "                         'w': 0.024514338575393153},\n",
      "                    21: {'a': 0.00046253469010175765,\n",
      "                         'c': 0.024514338575393153,\n",
      "                         'n': 0.00046253469010175765,\n",
      "                         's': 0.17067530064754857,\n",
      "                         'v': 0.503700277520814,\n",
      "                         'y': 0.3001850138760407},\n",
      "                    22: {'d': 0.3057354301572618,\n",
      "                         'g': 0.3427382053654024,\n",
      "                         'l': 0.00786308973172988,\n",
      "                         'm': 0.017113783533765033,\n",
      "                         'p': 0.20027752081406106,\n",
      "                         'u': 0.12627197039777982}},\n",
      "       'probability': 0.38199858256555635}}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(bayes_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## classify\n",
    "\n",
    "This function classifies a set of observations using a pre-trained Naive Bayes Classifier (NBC). For each observation, it calculates the probability score for each possible label based on the features and selects the label with the highest score. If the labeled flag is set to `True`, it includes the actual label in the results for comparison.\n",
    "\n",
    "### Args:\n",
    "* **nbc** : A dictionary representing the trained Naive Bayes Classifier. Each key is a label, and each value is a dictionary containing:\n",
    "  - **'probability'** : The prior probability of the label.\n",
    "  - **'features'** : A dictionary where each feature index maps to a dictionary of feature values and their respective probabilities.\n",
    "* **observations** : A list of lists, where each inner list represents an observation. The first element of each observation is the actual label (if labeled).\n",
    "* **labeled** : A boolean flag indicating whether the actual label is included in the results. Default is `True`.\n",
    "\n",
    "### Returns:\n",
    "* **results** : A list of predictions. If labeled is `True`, each element is a tuple containing the predicted label and the actual label; otherwise, each element is the predicted label alone.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(nbc, observations, labeled=True):\n",
    "    results = []\n",
    "    for observation in observations:\n",
    "        label_scores = {}\n",
    "        for label in nbc:\n",
    "            score = nbc[label]['probability']\n",
    "            for i in range(1, len(observation)):\n",
    "                feature_value = observation[i]\n",
    "                feature_probs = nbc[label]['features'][i]\n",
    "                score *= feature_probs.get(feature_value, 1.0)\n",
    "            label_scores[label] = score\n",
    "        predicted_label = max(label_scores, key=label_scores.get)\n",
    "        if labeled:\n",
    "            results.append((predicted_label, observation[0]))\n",
    "        else:\n",
    "            results.append(predicted_label)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluate\n",
    "\n",
    "This function calculates the error rate of a model's predictions by comparing the predicted labels to the actual labels in the labeled dataset.\n",
    "\n",
    "### Args:\n",
    "* **predicted_labels** : A list of lists where each inner list contains the predicted label for a given observation.\n",
    "* **labeled_data** : A list of lists representing the labeled data, where the first element of each inner list is the actual label.\n",
    "\n",
    "### Returns:\n",
    "* **error_rate** : A float representing the proportion of incorrectly predicted labels, calculated as the number of errors divided by the total number of observations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(predicted_labels, labeled_data):\n",
    "    errors = 0\n",
    "    n = len(labeled_data)\n",
    "    for i in range(n):\n",
    "        actual_label = labeled_data[i][0]\n",
    "        predicted_label = predicted_labels[i][0]\n",
    "        if predicted_label != actual_label:\n",
    "            errors += 1\n",
    "    error_rate = errors / n\n",
    "    return error_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = classify(bayes_classifier,cleaned_data,labeled=True)\n",
    "error_rate = evaluate(cleaned_data,results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02303330970942594\n"
     ]
    }
   ],
   "source": [
    "print(error_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train_and_evaluate\n",
    "\n",
    "This function trains a model using the provided training function, then classifies the test data using the provided classification function, and finally evaluates the model's performance using the provided evaluation function. It returns the error rate on the test data.\n",
    "\n",
    "### Args:\n",
    "* **train_fn** : A function used to train the model, taking the training data as input.\n",
    "* **classify_fn** : A function used to classify observations, taking the model and the test data as inputs.\n",
    "* **evaluate_fn** : A function used to evaluate the model's performance, taking the predicted labels and labeled test data as inputs.\n",
    "* **train_fold** : A list of lists representing the training data.\n",
    "* **test_fold** : A list of lists representing the test data. The first element of each observation is the actual label.\n",
    "\n",
    "### Returns: \n",
    "* **returns test_error** The error rate of the model on the test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(train_fn, classify_fn, evaluate_fn, train_fold, test_fold):\n",
    "    model = train_fn(train_fold)\n",
    "    predicted_test_labels = classify_fn(model, test_fold, labeled=True)\n",
    "    test_error = evaluate_fn(predicted_test_labels, test_fold)\n",
    "    return test_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate_and_print_mean\n",
    "\n",
    "This function calculates the mean test error rate across multiple folds and prints the result with four decimal places of precision.\n",
    "\n",
    "### Args:\n",
    "* **total_test_error_rate** : The sum of test error rates from all folds.\n",
    "* **num_folds** : The number of folds used in the evaluation.\n",
    "\n",
    "### Returns:\n",
    "* **None** : This function does not return any value. It prints the mean test error rate to the console.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_and_print_mean(total_test_error_rate, num_folds):\n",
    "    mean_test_error_rate = total_test_error_rate / num_folds\n",
    "    print(f\"Mean = {mean_test_error_rate:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cross_validate\n",
    "\n",
    "This function performs cross-validation on the provided dataset by splitting the data into 10 folds. It trains and evaluates a model for each pair of consecutive folds, printing the error rate for each pair. It also calculates and prints the mean test error rate across all folds.\n",
    "\n",
    "### Args:\n",
    "* **data** : List of lists, where each inner list represents an observation in the dataset. The first element of each observation is the label.\n",
    "* **train_fn** : A function used to train the model, taking the training data as input.\n",
    "* **classify_fn** : A function used to classify observations, taking the model and the test data as inputs.\n",
    "* **evaluate_fn** : A function used to evaluate the model's performance, taking the predicted labels and labeled test data as inputs.\n",
    "\n",
    "### Returns:\n",
    "* **None** : This function does not return any value. It prints the error rates for each pair of folds and the mean test error rate across all folds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(data, train_fn, classify_fn, evaluate_fn):    \n",
    "    total_test_error_rate = 0\n",
    "    folds = create_folds(data, 10)\n",
    "    print(\"Train   Test\")\n",
    "    for i in range(0, 10, 2):\n",
    "        fold_train = folds[i]\n",
    "        fold_test = folds[i + 1]\n",
    "        test_error1 = train_and_evaluate(train_fn, classify_fn, evaluate_fn, fold_train, fold_test)\n",
    "        print(f\"Fold {i + 1} -> Fold {i + 2} error rate: {test_error1:.4f}\")\n",
    "        test_error2 = train_and_evaluate(train_fn, classify_fn, evaluate_fn, fold_test, fold_train)\n",
    "        print(f\"Fold {i + 2} -> Fold {i + 1} error rate: {test_error2:.4f}\")\n",
    "        total_test_error_rate += test_error1 + test_error2\n",
    "    calculate_and_print_mean(total_test_error_rate, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train   Test\n",
      "Fold 1 -> Fold 2 error rate: 0.0885\n",
      "Fold 2 -> Fold 1 error rate: 0.0531\n",
      "Fold 3 -> Fold 4 error rate: 0.0743\n",
      "Fold 4 -> Fold 3 error rate: 0.0496\n",
      "Fold 5 -> Fold 6 error rate: 0.0532\n",
      "Fold 6 -> Fold 5 error rate: 0.0355\n",
      "Fold 7 -> Fold 8 error rate: 0.0691\n",
      "Fold 8 -> Fold 7 error rate: 0.0674\n",
      "Fold 9 -> Fold 10 error rate: 0.0479\n",
      "Fold 10 -> Fold 9 error rate: 0.0674\n",
      "Mean = 0.0606\n"
     ]
    }
   ],
   "source": [
    "data = parse_data(\"agaricus-lepiota-1.data\")\n",
    "training_data = remove_rows_with_missing_values(data)\n",
    "cross_validate(training_data, train, classify, evaluate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "en605645",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "81px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
